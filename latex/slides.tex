\documentclass[12pt]{beamer}

\author{Jake Humphrey}
\title{A Stochastic Computational Approach for Accurate and Efficient Reliability Evaluation}
\subtitle{A Python Implementation}
\institute{Department of Electronic and Electrical Engineering\\
  Imperial College London\\
  \texttt{jbh111@ic.ac.uk}
}

\begin{document}

\begin{frame}[plain]
  \titlepage
\end{frame}

\begin{frame}{Reliability of Circuits}
Gates in a logic circuit are, alas, not perfect. They are susceptible to error, of which there are three main types:
\begin{itemize}
\item \textbf{Stuck-At-One Error:} The output of the gate goes high, regardless of the expected output.
\item \textbf{Stuck-At-Zero Error:} The output of the gate goes low, regardless of the expected output.
\item \textbf{Von Neumann Error:} The output of the gate becomes the inverse of the expected output.
\end{itemize}
\end{frame}

\begin{frame}{Masking Effects}
However, there is a chance that errors in one gate will not propagate all the way to an output. This could be due to one of the following \emph{masking effect}s
\begin{itemize}
\item \textbf{Electrical Masking:} The error does not have a large enough effect on the amplitude of the logic signal to be detected at an input.
\item \textbf{Temporal Masking:} The error is input to a latch but occurs at some point in time outside of the latch's detection window.
\item \textbf{Logical Masking:} The error does not pass through a multi-input logic gate because the value of the other input(s) fix(es) the output of the gate.
\end{itemize}
\end{frame}
\begin{frame}{Reliability Analysis \small Principles}
As it happens, Logical Masking is the most prominent masking type in logical circuits. It is therefore useful to be able to analyse circuits on their ability to logically mask errors.
\vspace{0.25cm}

If we define the \emph{probability} of a signal as the proportion of time that it is logically True, then the basic idea is as follows:
\begin{itemize}
\item Construct a faulty representation of the circuit, which takes into account probabilities of each gate failing.
\item Derive the probabilities of the output signals.% in terms of the input probabilities and gate error probabilities for both the ideal and faulty circuits.
\item Then the \emph{reliability} of an output signal is the probability that it takes the same value in both the ideal and faulty circuits.
\end{itemize}
\end{frame}

\begin{frame}{Reliability Analysis \small Probabilistic Gate Models}
However, existing algorithms are inefficient!
\vspace{0.25cm}

For example, \emph{Probabilistic Gate Models} (PGMs) attempt to analytically derive the output probabilities as functions of the input probabilities and gate error probabilities. 
\vspace{0.25cm}

The problem occurs when the inputs to a gate are not statistically independent, such as is the case when there are \emph{reconvergent fanouts}. That is, when two or more inputs to a gate originated from a single signal.
\vspace{0.25cm}

The PGM equations do not account for statistically dependent signals, and the solution involves splitting the circuit into two sub-circuits. This approximately doubles the cost of the algorithm for each reconvergent fanout.
\end{frame}

\begin{frame}{Reliability Analysis \small Stochastic Logic with Bernoulli Sequences}
The use of \emph{Stochastic Logic} can avoid these issues. With this approach, the input probabilities are used to generate input bitstreams, which are then propagated through the circuit. The output probabilities can then be accurately calculated from the output bitstreams.
\vspace{0.25cm}

Existing algorithms use the input probabilities to generate \emph{Bernoulli Sequences}, where each element is a Bernoulli distributed random variable, the parameter for which is the input probability.
\vspace{0.25cm}

However, this approach incurs a large computational overhead, as a random number must be generated for each element, for each input. This can be significant for large circuits, because the input sequences must be large to obtain accurate results.
\end{frame}

\begin{frame}{Reliability Analysis \small Stochastic Logic with Non-Bernoulli Sequences}
To reduce the random number generation overhead, \emph{Non-Bernoulli Sequences} can be used.
\vspace{0.25cm}

These sequences are generated deterministically with the expected number of 1s, and then randomly permuted.
\vspace{0.25cm}

This means only one random number generation is required per input bitstream.
\end{frame}
\end{document}